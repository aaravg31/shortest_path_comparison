\documentclass[acmsmall]{acmart}

% Remove ACM copyright/journal footers
\settopmatter{printacmref=false}
\renewcommand\footnotetextcopyrightpermission[1]{}
\pagestyle{plain}

\usepackage{subcaption}
\usepackage{float}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}

\begin{document}

\title{Shortest Path Algorithm Comparisons: Dijkstra with Advanced Heaps and Bidirectional Skewness}

\author{Aarav Gosalia}
\affiliation{%
  \institution{University of British Columbia Okanagan}
  \city{Kelowna}
  \country{Canada}}

\author{Riley Eaton}
\affiliation{%
  \institution{University of British Columbia Okanagan}
  \city{Kelowna}
  \country{Canada}}

\begin{abstract}
This report presents a comparative analysis of several variants of Dijkstra’s shortest path algorithm, focusing on both priority queue design and search strategy. We implement Dijkstra’s algorithm with three different heap-based priority queues: Binary Heap, Radix Heap, and Fibonacci Heap, and also study a bidirectional Dijkstra variant with skewed search frontiers. All data structures are implemented from scratch in Python and evaluated on large randomly generated weighted graphs designed to approximate real-world network structure. Theoretical time and space bounds are contrasted with empirical behaviour, using both runtime and peak memory usage as primary metrics.

[Results summary to be completed once experiments are finalized.]
\end{abstract}

\keywords{Dijkstra’s Algorithm, Binary Heap, Radix Heap, Fibonacci Heap, Bidirectional Skewness, Graph Algorithms, Priority Queues}

\maketitle

\section{Introduction}

Dijkstra’s shortest path algorithm remains one of the most influential and widely used algorithms in graph theory, powering applications in transportation networks, communication systems, robotics, and large-scale optimization. Although the algorithmic structure of Dijkstra’s method is conceptually simple, its real-world performance is deeply dependent on the efficiency of the priority queue used to repeatedly extract the next closest vertex and perform decrease\_key operations.

\vspace{1em}

This report examines and compares three priority queue data structures that can be used to optimize Dijkstra’s algorithm:

\begin{enumerate}
  \item \textbf{Binary Heap} – A widely used baseline implementation offering $O(\log n)$ extract\_min and decrease\_key, forming the standard version taught in most courses.
  
  \item \textbf{Fibonacci Heap} – A theoretically optimal structure with $O(1)$ amortized decrease\_key and $O(\log n)$ extract\_min, often cited for achieving Dijkstra’s best-known theoretical bound of $O(m + n \log n)$.
  
  \item \textbf{Radix Heap} – A monotone integer priority queue tailored for Dijkstra on graphs with non-negative edge weights. It exploits the fact that extracted distances are non-decreasing, achieving $O(1)$ amortized insert and decrease\_key, and $O(\log C)$ for extract\_min, where $C$ is the maximum key difference. This makes it highly efficient on graphs with bounded or small integer weights.
\end{enumerate}

In addition to these data structures, this project will also extend the analysis to include \textbf{Bidirectional Dijkstra with Skewed Expansion}, an optimization technique that explores the graph simultaneously from the source and the target. (ELABORATE HERE)

\vspace{1em}
Overall, the goal of this project is to provide both a theoretical and empirical comparison of these structures, evaluating their runtime behavior, scalability, and memory characteristics when applied to large synthetic graphs.

\section{Background and Theory}
This section discusses the underlying principles of Dijkstra’s algorithm, the priority queue data structures used to optimize it, and bidirectional skewness.

\subsection{Dijkstra’s Algorithm Overview}
Dijkstra’s algorithm finds the shortest path from a source node to all other nodes in a weighted graph with non-negative edge weights. It repeatedly extracts the node with the smallest tentative distance and updates its neighbors.  

The efficiency of Dijkstra’s algorithm largely depends on how the “next smallest distance” is retrieved and updated, i.e., on the efficiency of the \texttt{extract\_min} and \texttt{decrease\_key} operations. Therefore, the overall performance of Dijkstra’s algorithm depends directly on the choice of priority queue.

\subsection{Binary Heap}
A \textbf{Binary Heap} is a complete binary tree that satisfies the \emph{heap property} — each parent node’s key is smaller than or equal to the keys of its children (in a min-heap). Internally, it is most often implemented using an array where the element at index $i$ has:
\begin{itemize}
  \item Left child at index $2i + 1$
  \item Right child at index $2i + 2$
  \item Parent at index $\lfloor (i - 1)/2 \rfloor$
\end{itemize}

This array-based representation eliminates the need for pointers, making Binary Heaps both memory efficient and cache friendly. Figure~\ref{fig:binaryheap} illustrates how the same heap structure can be represented in both array and tree form.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\linewidth]{plots/binary_heap.png}
  \caption{Binary Heap: array-based and pictorial representations (adapted from GeeksforGeeks~\cite{geeksforgeeks_binaryheap}).}
  \label{fig:binaryheap}
\end{figure}

\subsubsection*{Insertion}
When a new element is inserted, it is first placed at the end of the array (to maintain the complete tree property). Then, it is repeatedly compared with its parent and swapped upward until the heap property is restored. This upward movement is known as a \textbf{sift-up} or \textbf{bubble-up}.  
Since each level in the tree can contain twice as many nodes as the previous one, and the heap’s height is $\log_2 n$, the insertion process requires at most $\log n$ swaps.  
\[
T_{\text{insert}} = O(\log n)
\]

\subsubsection*{Extract\_Min}
Extracting the minimum element involves removing the root (the smallest key). To maintain completeness, the last element in the array is moved to the root position. Then, it is repeatedly swapped with the smaller of its two children until the heap property is restored. This process is called \textbf{sift-down} or \textbf{heapify}.  
Each swap moves the element one level deeper, and the tree height is $\log n$, so the operation takes logarithmic time.  
\[
T_{\text{extract\_min}} = O(\log n)
\]

\subsubsection*{decrease\_Key}
The \texttt{decrease\_key} operation lowers the key value of an element in the heap. Because the key becomes smaller, the node may violate the heap property with respect to its parent. Therefore, the element is moved upward using the same \textbf{sift-up} procedure as insertion. In the worst case, it moves up to the root, resulting in logarithmic time.  
\[
T_{\text{decrease\_key}} = O(\log n)
\]

\subsubsection*{Space Complexity}
A Binary Heap stores all elements in a single contiguous array, which makes its space usage straightforward to analyze. The heap requires one array slot per element, leading to a total memory footprint of
\[
O(n)
\]
where $n$ is the number of elements in the heap.

Because the array representation avoids pointers entirely, Binary Heaps have excellent spatial locality and minimal per-node overhead compared to pointer-based structures such as Fibonacci Heaps. This contiguous layout also makes them cache-friendly, which contributes to their strong practical performance despite having asymptotically slower operations than more advanced heaps.

\vspace{1em}
Binary Heaps are conceptually simple, have small constant factors, and perform well in practice due to their contiguous memory layout. They are the default choice for most implementations of Dijkstra’s algorithm in production systems. However, their performance can degrade for dense graphs where the number of \texttt{decrease\_key} operations is large, motivating more advanced structures such as the \textbf{Radix Heap} and \textbf{Fibonacci Heap}.

\subsection{Fibonacci Heap}
A \textbf{Fibonacci Heap} is an advanced data structure that improves the efficiency of priority queue operations through a collection of \emph{heap-ordered trees}. Unlike Binary Heaps, it performs most operations in constant amortized time by deferring expensive structural adjustments until absolutely necessary.  

Each tree in a Fibonacci Heap obeys the \emph{min-heap property}: the key of every node is greater than or equal to that of its parent. The heap maintains a circular doubly linked list of all tree roots (the \emph{root list}), with a pointer to the minimum key node.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\linewidth]{plots/fibonacci_heap.png}
  \caption{Example of a Fibonacci Heap with multiple trees in the root list. The node with key 3 is the global minimum (adapted from GeeksforGeeks~\cite{geeksforgeeks_fibonacciheap}).}
  \label{fig:fibonacciheap}
\end{figure}

\subsubsection*{Insertion}
To insert a new key, a single-node tree is created and added directly to the root list. The minimum pointer is updated if the new key is smaller than the current minimum.  
Since no tree restructuring or traversal is required, the insertion operation runs in \textbf{constant time}.  
\[
T_{\text{insert}} = O(1)
\]

\subsubsection*{Extract\_Min}
The \texttt{extract\_min} operation removes the node pointed to by the minimum pointer. Its children are then added to the root list, effectively promoting them to become separate trees. To restore the heap’s structure, trees in the root list with the same degree (number of children) are \textbf{consolidated} by linking one tree as a child of another with a smaller key.  

\begin{figure}[H]
  \centering
  \includegraphics[width=0.95\linewidth]{plots/fibonacci_heap2.png}
  \caption{Illustration of the \texttt{extract\_min} operation in a Fibonacci Heap. 
  The minimum node (3) is removed, and its children are added to the root list, followed by consolidation of trees with equal degree 
  (adapted from OpenGenus~\cite{opengenus_fibonacciheap}).}
  \label{fig:fibonacciheap_extractmin}
\end{figure}

The consolidation process ensures that the number of trees in the heap is logarithmic with respect to $n$, the total number of nodes. Therefore, while individual link operations are constant time, the entire \texttt{extract\_min} runs in amortized logarithmic time.  
\[
T_{\text{extract\_min}} = O(\log n)
\]

\subsubsection*{decrease\_Key}
The \texttt{decrease\_key} operation reduces the key value of a node. If the new key violates the heap property (i.e., becomes smaller than its parent), the node is \textbf{cut} from its parent and added to the root list.  
To maintain balance, if a parent loses more than one child, it is also cut, a process known as a \textbf{cascading cut}.  

Since cuts involve constant-time pointer manipulations, the amortized time for this operation remains constant.  
\[
T_{\text{decrease\_key}} = O(1)
\]

Fibonacci Heaps achieve remarkable theoretical efficiency, particularly for algorithms like Dijkstra’s, where \texttt{decrease\_key} is frequent. The overall complexity improves to:
\[
T(V, E) = O(E + V \log V)
\]
This is better than the $O(E \log V)$ bound of Binary Heaps.  

\vspace{1em}
However, in practice, Fibonacci Heaps might be slower due to their large constant factors and complex pointer manipulations. They are mainly of theoretical interest and in applications where the number of \texttt{decrease\_key} operations is exceptionally high. The implementation complexity also makes debugging and memory management more challenging compared to simpler structures like Binary Heaps.

\subsection{Radix Heap}

\subsection{BiDirectional Skewness}

\section{Methodology}
All three heaps, Binary, Radix, and Fibonacci, were implemented entirely in \textbf{Python 3} from scratch.  
Each heap defines a consistent interface to support Dijkstra’s algorithm, ensuring fair benchmarking and identical algorithmic behavior across all data structures.

Each heap class implements the following core methods:
\begin{itemize}
  \item \texttt{insert(node, priority)} – Inserts a node into the heap with its associated distance value.
  \item \texttt{extract\_min()} – Removes and returns the node with the smallest priority value.
  \item \texttt{decrease\_key(node, new\_priority)} – Updates a node’s priority when a shorter path is found.
  \item \texttt{is\_empty()} – Checks whether the heap contains any remaining nodes.
\end{itemize}

A unified implementation of Dijkstra’s algorithm was created in \texttt{dijkstra.py}, where the heap type can be switched dynamically:
\begin{verbatim}
dijkstra(graph, source, heap_type="binary")
\end{verbatim}

This modular design allows the same Dijkstra function to operate seamlessly with any heap type, enabling controlled comparisons of performance and runtime behavior under identical conditions.

\subsection{Graph Generation}
To test scalability, large random graphs were generated using a custom \texttt{graph\_generator.py} script located in the \texttt{utils} directory. Each graph is represented as a directed, weighted adjacency list:

\[
G = \{ u : [(v, w)], \ldots \}
\]

where each node $u$ maps to a list of tuples $(v, w)$, representing a directed edge from $u$ to $v$ with weight $w$ randomly drawn from the range $[1, 10]$.

\subsubsection*{Generation Process}
For each graph size, a specified number of nodes and an average number of outgoing edges per node were chosen.  
The generator computes the total number of edges approximately as:

\[
E \approx \text{avg\_edges\_per\_node} \times V
\]

For example, a graph with $V = 500{,}000$ nodes and $15$ average edges per node produces roughly $7.5$ million directed edges. Edges and weights are randomly assigned, and the process is visualized using the \texttt{tqdm}~\cite{tqdm} progress bar for large-scale runs.

The final experiments were conducted on four large-scale graphs of increasing size to evaluate scalability and runtime growth across different heap implementations.

\begin{itemize}
  \item 100K nodes → $\approx$ 1.2M edges  
  \item 500K nodes → $\approx$7.5M edges  
  \item 1M nodes → $\approx$20M edges  
  \item 2M nodes → $\approx$50M edges  
\end{itemize}

Larger graphs beyond 2 million nodes were not tested due to hardware constraints, specifically, the system’s 16GB memory capacity and the significant runtime required for dense graphs at that scale. Each graph was processed by the Dijkstra implementation using all three heap structures to record total execution time, enabling both theoretical and empirical performance comparisons.

\section{Results}
All experiments were executed on a MacBook Pro M2 (16 GB RAM) using wall-clock time to measure total runtime for each heap implementation. Each experiment was repeated \textbf{twice} to ensure consistency and reproducibility of results, minimizing the effect of system background processes or transient performance variations.

\begin{table}[H]
\centering
\caption{Runtime comparison of Dijkstra’s Algorithm using different heap implementations across two runs.}
\label{tab:runtimes}
\begin{tabular}{lcccccc}
\toprule
\textbf{Heap Type} & \textbf{Run} & \textbf{100K} & \textbf{500K} & \textbf{1M} & \textbf{2M} \\
\midrule
Binary Heap     & Run 1 & 0.77s & 6.55s & 15.29s & 237.31s \\
                 & Run 2 & 0.91s & 5.77s & 14.20s & 143.59s \\
\midrule
Radix Heap    & Run 1 & 0.76s & 6.31s & 13.80s & 152.58s \\
                 & Run 2 & 0.78s & 5.60s & 12.79s & 73.23s \\
\midrule
Fibonacci Heap  & Run 1 & 0.90s & 6.46s & 15.66s & 78.97s \\
                 & Run 2 & 0.86s & 5.91s & 14.73s & 50.16s \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{plots/runtime_comparison.png}
  \caption{Runtime comparison of Dijkstra’s Algorithm (Run 1)}
  \label{fig:runtime1}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{plots/runtime_comparison_log.png}
  \caption{Runtime comparison of Dijkstra’s Algorithm (Run 2)}
  \label{fig:runtime2}
\end{figure}

\section{Visualization}

The visualization system uses the Pygame library to provide an interactive, real-time comparison of shortest path algorithms on a customizable grid-based graph. 

Each algorithm is implemented as a Python generator that yields intermediate states at each iteration. The grid is represented as an $N \times N$ matrix of nodes, which is converted to an adjacency list for algorithm execution. During visualization, nodes are color-coded to reflect their state: orange for the start node, turquoise for the end, black for obstacles, red for visited nodes, green for frontier nodes, and purple for the final shortest path. This allows users to observe how each algorithm explores the search space differently—Dijkstra expands uniformly from the source, Bidirectional Dijkstra searches from both endpoints simultaneously, and Contraction Hierarchies shows very little exploration due to its preprocessing. For Contraction Hierarchies specifically, the visualization includes gold lines connecting nodes with shortcuts, demonstrating how the algorithm "jumps" across the graph using preprocessed edges before unpacking them into the complete path. 

To provide accurate performance comparisons without visualization overhead, each algorithm runs twice: first non-visually to capture timing metrics, then as a generator for step-by-step rendering. The system supports command-line configuration of grid size and heap type (binary, Fibonacci, or radix), allowing users to easily compare different configurations. Users interact using mouse clicks to place walls and start/end nodes, with keyboard controls for algorithm selection and execution. Preset mazes and random wall generation allow for repeatable and rapid testing, respectively. 

This visualization tool serves as both an educational resource for understanding algorithmic behavior and a practical benchmarking environment to analyze performance for different graph structures.

\section{Discussion}

\section{Conclusion}

\section*{GitHub Repository}
The full implementation (data structures, Dijkstra’s algorithm, unit tests, and benchmark plots) is available at:  
\url{https://github.com/aaravg31/shortest_path_comparison}

\section*{Acknowledgements}
We would like to acknowledge ChatGPT \cite{chatgpt} for assistance with code explanations, debugging, and report language refinement.

\bibliographystyle{ACM-Reference-Format}
\bibliography{refs}

\end{document}

